{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Existen diversas técnicas de recolección de datos, dependiendo del tipo de investigación, del objetivo y de la fuente de los datos.\n",
        "1. **Encuestas:**\n",
        "Se utilizan para recopilar información de grandes grupos de personas de manera estructurada.\n",
        "Métodos: Cuestionarios online, telefónicos, presenciales, o en papel.\n",
        "Ventaja: Permiten recolectar datos cuantitativos y cualitativos de una gran muestra en poco tiempo.\n",
        "Ejemplo: Encuestas de satisfacción del cliente.\n",
        "2. **Entrevistas**\n",
        "Diálogo entre el entrevistador y el entrevistado para obtener información detallada.\n",
        "Tipos: Estructuradas (preguntas fijas), semi-estructuradas (flexibles) o no estructuradas (conversacionales).\n",
        "Ventaja: Aportan información profunda y detallada sobre la percepción de los participantes.\n",
        "Ejemplo: Entrevistas para estudios de mercado o investigaciones académicas.\n",
        "3. **Observación**\n",
        "Consiste en observar directamente el comportamiento de los sujetos en su entorno natural.\n",
        "Tipos: Observación participante (el investigador se involucra) o no participante (observa sin intervenir).\n",
        "Ventaja: Permite obtener información no verbal y sobre comportamientos espontáneos.\n",
        "Ejemplo: Estudio del comportamiento de los clientes en una tienda.\n",
        "4. **Experimentos**\n",
        "Se manipulan variables en un entorno controlado para observar los efectos en las variables dependientes.\n",
        "Ventaja: Proporciona datos más objetivos y permite identificar relaciones de causa-efecto.\n",
        "Ejemplo: Pruebas A/B en marketing digital para ver qué variante de una campaña tiene más éxito.\n",
        "5. **Grupos Focales (Focus Groups)**\n",
        "Reunión de un pequeño grupo de personas para discutir un tema específico bajo la guía de un moderador.\n",
        "Ventaja: Genera información cualitativa rica, obtenida a través de la interacción grupal.\n",
        "Ejemplo: Evaluación de la percepción de un producto antes de su lanzamiento.\n",
        "6. **Recolección de Datos Automatizada (Web Scraping)**\n",
        "Uso de software para extraer grandes volúmenes de datos de sitios web.\n",
        "Ventaja: Recoge datos de manera rápida y eficiente desde fuentes online.\n",
        "Ejemplo: Extracción de precios de productos en tiendas online.\n",
        "7. **Análisis de Datos Secundarios**\n",
        "Se utilizan datos que ya han sido recopilados y publicados por otras fuentes, como informes, censos, bases de datos públicas, etc.\n",
        "Ventaja: Ahorra tiempo y costos en la recolección de datos.\n",
        "Ejemplo: Uso de estadísticas gubernamentales para análisis demográficos.\n",
        "8. **Diarios o Bitácoras**\n",
        "Los participantes registran regularmente sus actividades, pensamientos o comportamientos en un diario.\n",
        "Ventaja: Permite captar información continua en un período determinado.\n",
        "Ejemplo: Diarios de alimentación para estudios nutricionales.\n",
        "9. **Sensores o Dispositivos Electrónicos**\n",
        "Recolección de datos mediante sensores o dispositivos que registran automáticamente las mediciones.\n",
        "Ventaja: Datos precisos y objetivos en tiempo real.\n",
        "Ejemplo: Sensores de calidad del aire, medidores de tráfico o dispositivos de monitoreo de salud."
      ],
      "metadata": {
        "id": "5kwAU0YTkYBu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Plan de recoleccion de  datos**"
      ],
      "metadata": {
        "id": "SlQnUz_zlpoW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Definición del Objetivo\n",
        "Objetivo general: Recolectar y analizar datos sobre libros disponibles en sitios web para entender tendencias de precios, disponibilidad y popularidad de diferentes títulos.\n",
        "Objetivo específico: Extraer el título, precio y disponibilidad de libros de diferentes categorías para crear un dataset que sirva para análisis posteriores, como comparaciones de precios o clasificaciones.\n",
        "2. Identificación de la Fuente de Datos\n",
        "Sitios web seleccionados:\n",
        "Books to Scrape: Utilizaremos este sitio para obtener información sobre libros como títulos, precios, disponibilidad y categorías.\n",
        "Frecuencia de recolección:\n",
        "Inicialmente: Se recolectarán datos una vez por semana durante un mes para analizar las variaciones.\n",
        "Ajuste futuro: Dependiendo del análisis inicial, podríamos ajustar la frecuencia de recolección si se detectan cambios significativos en los datos (por ejemplo, promociones o actualizaciones frecuentes de productos).\n",
        "3. Variables a Extraer\n",
        "Título: Nombre del libro.\n",
        "Precio: Precio del libro en la página web.\n",
        "Disponibilidad: Estado de inventario, es decir, si el libro está disponible para la compra.\n",
        "Categoría: Clasificación del libro en la página web, lo que permitirá segmentar la información.\n",
        "Calificación: Puntuación del libro, si está disponible.\n",
        "4. Método de Recolección de Datos\n",
        "Herramientas:\n",
        "Lenguaje de programación: Python.\n",
        "Librerías:\n",
        "requests para obtener el contenido de la página web.\n",
        "BeautifulSoup para analizar el HTML y extraer los datos.\n",
        "pandas para estructurar los datos y guardarlos en CSV para análisis posteriores.\n",
        "Proceso:\n",
        "Realizar solicitudes HTTP a la página principal y a las diferentes páginas de categorías de libros.\n",
        "Extraer el HTML usando BeautifulSoup para identificar los elementos que contienen los títulos, precios y disponibilidad.\n",
        "Repetir este proceso para todas las categorías y páginas del sitio.\n",
        "Guardar los datos en un archivo CSV o base de datos para su análisis.\n",
        "5. Plan de Automatización\n",
        "Para garantizar que la recolección de datos sea constante y eficiente, se puede utilizar una tarea programada para que el script de scraping se ejecute automáticamente. Esto puede hacerse utilizando cron jobs en sistemas basados en Unix o Task Scheduler en Windows.\n",
        "Frecuencia programada: Ejecutar el script semanalmente para capturar nuevas variaciones en los precios y en la disponibilidad de los libros.\n",
        "6. Manejo y Almacenamiento de los Datos\n",
        "Almacenamiento:\n",
        "Se utilizarán archivos CSV para almacenar los datos recolectados.\n",
        "Para proyectos más avanzados, se puede considerar el uso de una base de datos como MySQL o SQLite para guardar los datos.\n",
        "Estructura del archivo CSV:\n",
        "El archivo incluirá las siguientes columnas: Title, Price, Availability, Category, Rating.\n",
        "Control de versiones: Es recomendable incluir una columna Date para marcar la fecha de recolección de los datos, lo que permitirá hacer un seguimiento temporal de los cambios.\n",
        "7. Consideraciones Éticas y Legales\n",
        "Dado que Books to Scrape es un sitio diseñado para el web scraping, no hay restricciones legales. Si el scraping se hace en otros sitios, será importante revisar el archivo robots.txt y los términos de servicio para asegurarse de que el scraping esté permitido.\n",
        "Recomendación: Limitar la frecuencia de las solicitudes para no sobrecargar el servidor del sitio.\n",
        "8. Evaluación de la Calidad de los Datos\n",
        "Verificación de errores: Implementar mecanismos para verificar si los datos están completos y sin errores (por ejemplo, verificar que los precios y los títulos hayan sido extraídos correctamente).\n",
        "Recolección fallida: En caso de que una página web esté caída o se produzca un error en la recolección, se puede registrar en un archivo de logs el error para tomar acciones correctivas.\n",
        "9. Análisis y Visualización de los Datos\n",
        "Análisis preliminar: Se analizarán los datos recolectados para identificar tendencias como la variación de precios entre categorías o la disponibilidad de los libros.\n",
        "Herramientas: Utilizar pandas para el análisis de los datos y matplotlib o seaborn para la visualización de los resultados.\n",
        "Informe final: Una vez obtenidos los datos y su análisis, se puede generar un informe que detalle las conclusiones sobre las tendencias de precios y la disponibilidad de libros.\n",
        "10. Posibles Ajustes y Mejoras\n",
        "Si se detectan páginas bloqueadas o cambios en la estructura del HTML, se realizarán ajustes en el script de scraping.\n",
        "Explorar otros sitios similares para ampliar la cantidad de datos y obtener comparaciones entre varias fuentes.\n",
        "Conclusión\n",
        "Este plan de recolección de datos a través de web scraping te permitirá obtener datos actualizados y relevantes sobre libros, su precio y su disponibilidad. La frecuencia semanal proporcionará una visión dinámica de los cambios en el inventario y los precios, lo que puede ser útil para análisis de tendencias a lo largo del tiempo."
      ],
      "metadata": {
        "id": "D-qC8Dbqln4P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Configuración del Entorno"
      ],
      "metadata": {
        "id": "8XrbJ6T1mRCf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install beautifulsoup4 requests pandas\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfuhRXxhmSu5",
        "outputId": "4151be10-99c8-4bd1-ccb8-4410afff739e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Código para Recolección de Datos"
      ],
      "metadata": {
        "id": "X8kWqxjbmdT3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# URL principal del sitio\n",
        "base_url = 'http://books.toscrape.com/catalogue/page-{}.html'\n",
        "\n",
        "# Listas para almacenar los datos\n",
        "titles = []\n",
        "prices = []\n",
        "availabilities = []\n",
        "categories = []\n",
        "ratings = []\n",
        "\n",
        "# Iteramos a través de las primeras 5 páginas (ajusta este número según sea necesario)\n",
        "for page in range(1, 6):\n",
        "    url = base_url.format(page)\n",
        "    response = requests.get(url)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Encontramos todos los libros en la página\n",
        "        books = soup.find_all('article', class_='product_pod')\n",
        "\n",
        "        for book in books:\n",
        "            # Extraemos el título del libro\n",
        "            title = book.h3.a['title']\n",
        "            titles.append(title)\n",
        "\n",
        "            # Extraemos el precio del libro\n",
        "            price = book.find('p', class_='price_color').text\n",
        "            prices.append(price)\n",
        "\n",
        "            # Extraemos la disponibilidad del libro\n",
        "            availability = book.find('p', class_='instock availability').text.strip()\n",
        "            availabilities.append(availability)\n",
        "\n",
        "            # Extraemos la categoría (desde la página principal no está disponible directamente, pero podemos agregar una categoría de ejemplo o extraerla de otra parte si expandimos el scraping)\n",
        "            category = 'Books'  # Dato ficticio para este ejemplo\n",
        "            categories.append(category)\n",
        "\n",
        "            # Extraemos la calificación (basada en clases de estrellas)\n",
        "            rating = book.p['class'][1]  # La calificación está en la segunda clase del elemento <p>\n",
        "            ratings.append(rating)\n",
        "\n",
        "    else:\n",
        "        print(f\"Error al acceder a la página {page}: {response.status_code}\")\n",
        "\n",
        "# Creamos un DataFrame con los datos extraídos\n",
        "df = pd.DataFrame({\n",
        "    'Title': titles,\n",
        "    'Price': prices,\n",
        "    'Availability': availabilities,\n",
        "    'Category': categories,\n",
        "    'Rating': ratings\n",
        "})\n",
        "\n",
        "# Guardamos el DataFrame en un archivo CSV\n",
        "df.to_csv('books_data.csv', index=False)\n",
        "\n",
        "# Mostramos un resumen de los datos\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIfRtOXFmk8v",
        "outputId": "4da99499-e152-42ae-c99d-379e15058d61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                   Title    Price Availability Category Rating\n",
            "0                   A Light in the Attic  Â£51.77     In stock    Books  Three\n",
            "1                     Tipping the Velvet  Â£53.74     In stock    Books    One\n",
            "2                             Soumission  Â£50.10     In stock    Books    One\n",
            "3                          Sharp Objects  Â£47.82     In stock    Books   Four\n",
            "4  Sapiens: A Brief History of Humankind  Â£54.23     In stock    Books   Five\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Descripción del Código\n",
        "Iteración por páginas: Se raspan las primeras 5 páginas del sitio web. Puedes ajustar el rango de for page in range(1, 6) para aumentar o disminuir el número de páginas que se desean recolectar.\n",
        "Datos extraídos:\n",
        "Título: El nombre del libro.\n",
        "Precio: El precio del libro en la moneda que aparece en la página.\n",
        "Disponibilidad: El estado de stock del libro.\n",
        "Categoría: En este caso, para simplificar, se asigna una categoría genérica, pero se podría extender para extraer la categoría real navegando dentro de los enlaces.\n",
        "Calificación: Basada en las estrellas asignadas a cada libro (extraído a partir de las clases CSS).\n",
        "## 4. Ejecución del Código\n",
        "Ejecuta este script en tu entorno de trabajo (Google Colab o en tu sistema local). El script raspará los datos de las primeras 5 páginas y guardará la información en un archivo CSV llamado books_data.csv.\n",
        "## 5. Ajustes Futuros\n",
        "Frecuencia: Si deseas que este scraping se realice de manera periódica, podrías utilizar un cron job (en Linux/macOS) o el Programador de tareas (en Windows).\n",
        "Más categorías: Si deseas extraer más categorías de libros, puedes expandir el scraping para navegar en cada categoría desde la página principal.\n",
        "## 6. Revisión de los Datos\n",
        "El archivo CSV que generes (books_data.csv) contendrá la información de los libros extraídos. Puedes revisarlo con cualquier editor de hojas de cálculo o directamente con pandas:"
      ],
      "metadata": {
        "id": "AW85G1Nlmssg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Cargar los datos recolectados\n",
        "df = pd.read_csv('books_data.csv')\n",
        "\n",
        "# Mostrar los primeros registros\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oWI4Dmsm8pX",
        "outputId": "38a3d5aa-1879-4968-e953-2b1d675dca64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                Title    Price Availability  \\\n",
            "0                                A Light in the Attic  Â£51.77     In stock   \n",
            "1                                  Tipping the Velvet  Â£53.74     In stock   \n",
            "2                                          Soumission  Â£50.10     In stock   \n",
            "3                                       Sharp Objects  Â£47.82     In stock   \n",
            "4               Sapiens: A Brief History of Humankind  Â£54.23     In stock   \n",
            "..                                                ...      ...          ...   \n",
            "95  Lumberjanes Vol. 3: A Terrible Plan (Lumberjan...  Â£19.92     In stock   \n",
            "96  Layered: Baking, Building, and Styling Spectac...  Â£40.11     In stock   \n",
            "97  Judo: Seven Steps to Black Belt (an Introducto...  Â£53.90     In stock   \n",
            "98                                               Join  Â£35.67     In stock   \n",
            "99          In the Country We Love: My Family Divided  Â£22.00     In stock   \n",
            "\n",
            "   Category Rating  \n",
            "0     Books  Three  \n",
            "1     Books    One  \n",
            "2     Books    One  \n",
            "3     Books   Four  \n",
            "4     Books   Five  \n",
            "..      ...    ...  \n",
            "95    Books    Two  \n",
            "96    Books    One  \n",
            "97    Books    Two  \n",
            "98    Books   Five  \n",
            "99    Books   Four  \n",
            "\n",
            "[100 rows x 5 columns]\n"
          ]
        }
      ]
    }
  ]
}